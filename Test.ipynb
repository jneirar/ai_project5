{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import imutils\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import math\n",
    "\n",
    "import gdown as gdown\n",
    "import zipfile\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "PATH = os.getcwd()\n",
    "letterToNumber = {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8, 'J': 9, 'K': 10, 'L': 11, 'M': 12, 'N': 13, 'O': 14, 'P': 15, 'Q': 16, 'R': 17, 'S': 18, 'T': 19, 'U': 20, 'V': 21, 'W': 22, 'X': 23, 'Y': 24, 'Z': 25}\n",
    "numberToLetter = {0: 'A', 1: 'B', 2: 'C', 3: 'D', 4: 'E', 5: 'F', 6: 'G', 7: 'H', 8: 'I', 9: 'J', 10: 'K', 11: 'L', 12: 'M', 13: 'N', 14: 'O', 15: 'P', 16: 'Q', 17: 'R', 18: 'S', 19: 'T', 20: 'U', 21: 'V', 22: 'W', 23: 'X', 24: 'Y', 25: 'Z'}\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1PGKJ4GU9yI1JVVddAtvuyhyPfL719BUG&export=download\n",
      "To: /Users/alessiayi/Documents/Github/Utec/ai_project5/Models/models.zip\n",
      "100%|██████████| 222M/222M [00:07<00:00, 30.5MB/s] \n"
     ]
    }
   ],
   "source": [
    "# Descarga los modelos entrenados\n",
    "'''url =  'https://drive.google.com/uc?id=18wmT6d4-5tAIuCeS4KkAzCg7yuSARy5m&export=download'\n",
    "output = 'Models/models.zip'\n",
    "gdown.download(url, output, quiet=False)\n",
    "with zipfile.ZipFile(PATH + \"/Models/models.zip\",\"r\") as zip_ref:\n",
    "    zip_ref.extractall(PATH + \"/Models/\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Models.Models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtener images = lista de np arrays que entran al modelo\n",
    "def preprocessing(image_name):\n",
    "    img = cv2.imread(PATH + \"\\\\\" + image_name)\n",
    "\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    ret, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1,1))\n",
    "    mask = cv2.morphologyEx(thresh, cv2.MORPH_DILATE, kernel)\n",
    "    conts = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    conts = imutils.grab_contours(conts)\n",
    "    boxes = []\n",
    "    for cntr in conts:\n",
    "        x,y,w,h = cv2.boundingRect(cntr)\n",
    "        cv2.rectangle(img, (x, y), (x+w, y+h), (0,0,255), 1)\n",
    "        boxes.append((x,y,w,h))\n",
    "    #plt.imshow(img)\n",
    "    #plt.show()\n",
    "    spaces = []\n",
    "\n",
    "    if (len(boxes) == 0):\n",
    "        return boxes, spaces\n",
    "    \n",
    "    boxes = sorted(boxes, key=lambda x: (x))\n",
    "    # print(len(boxes))\n",
    "    prom = 0\n",
    "    spaceLetters = []\n",
    "    for i in range(len(boxes)-1):\n",
    "        x = boxes[i][0]\n",
    "        y = boxes[i][1]\n",
    "        w = boxes[i][2]\n",
    "        h = boxes[i][3]\n",
    "        tmp = boxes[i+1][0]-(x+w)\n",
    "        prom+=tmp\n",
    "        spaceLetters.append(tmp)\n",
    "    if (len(boxes) > 1):\n",
    "        prom = prom/(len(boxes)-1) + 5\n",
    "    else:\n",
    "        prom = 0\n",
    "    # print(\"prom: \", math.ceil(prom))\n",
    "    for i in range(len(spaceLetters)):\n",
    "        # print(boxes[i+1][0]-(x+w), math.ceil(prom))\n",
    "        if (spaceLetters[i]) > math.ceil(prom):\n",
    "            spaces.append(i)\n",
    "\n",
    "    # print(spaces)\n",
    "    # cont = 0\n",
    "    images = []\n",
    "    for e, i in enumerate(boxes):\n",
    "        x = i[0]\n",
    "        y = i[1]\n",
    "        w = i[2]\n",
    "        h = i[3]\n",
    "        cropped = thresh[y:y+h, x:x+w]\n",
    "        # inverted = 255 - cropped\n",
    "        # print(cropped.shape)\n",
    "        height = cropped.shape[0]\n",
    "        width = cropped.shape[1]\n",
    "        if (height > width):\n",
    "            diff = height - width\n",
    "            padding = cv2.copyMakeBorder(cropped,30,30,30+int(diff/2),30+int(diff/2),cv2.BORDER_CONSTANT,value=[0,0,0])\n",
    "        elif (height == width):\n",
    "            padding = cv2.copyMakeBorder(cropped,30,30,30,30,cv2.BORDER_CONSTANT,value=[0,0,0])\n",
    "        else:\n",
    "            diff = width - height\n",
    "            padding = cv2.copyMakeBorder(cropped,30+int(diff/2),30+int(diff/2),30,30,cv2.BORDER_CONSTANT,value=[0,0,0])\n",
    "        resized = cv2.resize(padding, (28, 28))\n",
    "        for ii in range(resized.shape[0]):\n",
    "            for jj in range(resized.shape[1]):\n",
    "                if resized[ii][jj] > 0:\n",
    "                    resized[ii][jj] = 255\n",
    "        images.append(resized.astype('float32'))    \n",
    "        # if e < 9:\n",
    "        #plt.imshow(resized)\n",
    "        #plt.show()\n",
    "        # if cont in spaces:\n",
    "        #     blankSpace = np.zeros([28,28,1],dtype=np.uint8)\n",
    "        #     blankSpace.fill(255)\n",
    "        #     images.append(blankSpace.astype('float32'))  \n",
    "        #     plt.imshow(blankSpace)\n",
    "        #     plt.show()\n",
    "        # cont+=1\n",
    "    return images, spaces\n",
    "    print(len(images))\n",
    "    print(type(images[0]))\n",
    "    print(images[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testea\n",
    "def tester(images, spaces, model):\n",
    "    transformToTensor = transforms.ToTensor()\n",
    "    imageTensors = [transformToTensor(np.array(img)) for img in images]\n",
    "    imageBatch = torch.utils.data.DataLoader(dataset=imageTensors, batch_size=64, shuffle=False)\n",
    "\n",
    "    batch = 0\n",
    "    predictText = []\n",
    "    for imgBatch in imageBatch:\n",
    "        imgBatch = imgBatch.to(device)\n",
    "        labelBatchPred = model(imgBatch)\n",
    "\n",
    "        labelBatchPred = labelBatchPred.to('cpu')\n",
    "        imgBatch = imgBatch.to('cpu')\n",
    "        #print(labelBatchPred[0])\n",
    "        _, predBatch = torch.max(labelBatchPred, 1)\n",
    "\n",
    "        group = 0\n",
    "        n = len(imgBatch)\n",
    "        ok = 1\n",
    "        while(group < 4 and ok):\n",
    "            plt.figure(figsize = (25, 10))\n",
    "            r, c = 1, 16\n",
    "            for i in range(16):\n",
    "                plt.subplot(r, c, i+1)\n",
    "                plt.imshow(imgBatch[16*group + i].permute(1, 2, 0))\n",
    "                #plt.xlabel(str(64*batch + 16*group + i + 1) + \": \" + numberToLetter[predBatch[16*group + i].item()] + \" (\" + numberToLetter[np.argmax(y_data[16*group + i])] + \")\", fontsize = 15)\n",
    "                predictLetter = numberToLetter[predBatch[16*group + i].item()]\n",
    "                predictText.append(predictLetter)\n",
    "                plt.xlabel(str(64*batch + 16*group + i + 1) + \": \" + predictLetter,fontsize = 15)\n",
    "                if 16*group + i + 1 == n:\n",
    "                    ok = 0\n",
    "                    break\n",
    "            plt.show()\n",
    "            #print(\"\")\n",
    "            group += 1\n",
    "        batch += 1\n",
    "\n",
    "    finalText = \"\"\n",
    "    for i in range(len(predictText)):\n",
    "        finalText += predictText[i]\n",
    "        # print(predictText[i])\n",
    "        if i in spaces:\n",
    "            finalText += \" \"\n",
    "            # print(\" \")\n",
    "    return finalText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(1, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (11): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Linear(in_features=128, out_features=26, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carga el modelo y lo envia a device\n",
    "#model = torch.load(PATH + '/Models/AlexNet.pt', map_location=torch.device('cpu'))\n",
    "model1 = torch.load(PATH + '/Models/Lenet5.pt')\n",
    "model1 = model1.to(device)\n",
    "model1.eval()\n",
    "\n",
    "model2 = torch.load(PATH + '/Models/AlexNet.pt')\n",
    "model2 = model2.to(device)\n",
    "model2.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "\n",
    "def initiate_camera(seconds, out_name):\n",
    "    st = time.time()\n",
    "    iteration = 0\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        raise IOError(\"Cannot open webcam\")\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        # frame = cv2.resize(frame, None, fx = 0.5, fy = 0.5, interpolation=cv2.INTER_AREA)\n",
    "        cv2.imshow('Input', frame)\n",
    "        cur_time = time.time()\n",
    "        elapsed_time = cur_time - st\n",
    "\n",
    "        if elapsed_time > iteration * seconds:\n",
    "            cv2.imwrite(out_name, frame)\n",
    "            iteration += 1\n",
    "            #Aquí debería ir el código que manda la imagen (frame) al separador de letras.\n",
    "            images, spaces = preprocessing(out_name)\n",
    "            text1 = \"\"\n",
    "            text2 = \"\"\n",
    "            if len(images) > 0:\n",
    "                text1 = tester(images, spaces, model1)\n",
    "                text2 = tester(images, spaces, model2)\n",
    "            else:\n",
    "                text1 = \"\"\n",
    "                text2 = \"\"\n",
    "            #frame contiene la imagen como valor, y la imagen capturada como archivo se guarda en out_name\n",
    "            print(text1)\n",
    "            print(text2)\n",
    "        c = cv2.waitKey(1)\n",
    "        if c == 27:\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@15906.367] global /tmp/opencv-20220430-60527-1xmsjni/opencv-4.5.5/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('/Users/alessiayi/Documents/Github/Utec/ai_project5\\out.jpg'): can't open/read file: check file path/integrity\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.5) /tmp/opencv-20220430-60527-1xmsjni/opencv-4.5.5/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m/Users/alessiayi/Documents/Github/Utec/ai_project5/Test.ipynb Cell 9'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/alessiayi/Documents/Github/Utec/ai_project5/Test.ipynb#ch0000008?line=0'>1</a>\u001b[0m initiate_camera(\u001b[39m10\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mout.jpg\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "\u001b[1;32m/Users/alessiayi/Documents/Github/Utec/ai_project5/Test.ipynb Cell 8'\u001b[0m in \u001b[0;36minitiate_camera\u001b[0;34m(seconds, out_name)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alessiayi/Documents/Github/Utec/ai_project5/Test.ipynb#ch0000007?line=20'>21</a>\u001b[0m iteration \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alessiayi/Documents/Github/Utec/ai_project5/Test.ipynb#ch0000007?line=21'>22</a>\u001b[0m \u001b[39m#Aquí debería ir el código que manda la imagen (frame) al separador de letras.\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/alessiayi/Documents/Github/Utec/ai_project5/Test.ipynb#ch0000007?line=22'>23</a>\u001b[0m images, spaces \u001b[39m=\u001b[39m preprocessing(out_name)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alessiayi/Documents/Github/Utec/ai_project5/Test.ipynb#ch0000007?line=23'>24</a>\u001b[0m text1 \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/alessiayi/Documents/Github/Utec/ai_project5/Test.ipynb#ch0000007?line=24'>25</a>\u001b[0m text2 \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[1;32m/Users/alessiayi/Documents/Github/Utec/ai_project5/Test.ipynb Cell 5'\u001b[0m in \u001b[0;36mpreprocessing\u001b[0;34m(image_name)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/alessiayi/Documents/Github/Utec/ai_project5/Test.ipynb#ch0000004?line=1'>2</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpreprocessing\u001b[39m(image_name):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/alessiayi/Documents/Github/Utec/ai_project5/Test.ipynb#ch0000004?line=2'>3</a>\u001b[0m     img \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mimread(PATH \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m image_name)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/alessiayi/Documents/Github/Utec/ai_project5/Test.ipynb#ch0000004?line=4'>5</a>\u001b[0m     gray \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mcvtColor(img, cv2\u001b[39m.\u001b[39;49mCOLOR_BGR2GRAY)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/alessiayi/Documents/Github/Utec/ai_project5/Test.ipynb#ch0000004?line=5'>6</a>\u001b[0m     ret, thresh \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mthreshold(gray, \u001b[39m127\u001b[39m, \u001b[39m255\u001b[39m, cv2\u001b[39m.\u001b[39mTHRESH_BINARY_INV)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/alessiayi/Documents/Github/Utec/ai_project5/Test.ipynb#ch0000004?line=6'>7</a>\u001b[0m     kernel \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mgetStructuringElement(cv2\u001b[39m.\u001b[39mMORPH_RECT, (\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m))\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.5.5) /tmp/opencv-20220430-60527-1xmsjni/opencv-4.5.5/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "initiate_camera(10, \"out.jpg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
