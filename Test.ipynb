{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import imutils\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import math\n",
    "\n",
    "import gdown as gdown\n",
    "import zipfile\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "PATH = os.getcwd()\n",
    "letterToNumber = {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8, 'J': 9, 'K': 10, 'L': 11, 'M': 12, 'N': 13, 'O': 14, 'P': 15, 'Q': 16, 'R': 17, 'S': 18, 'T': 19, 'U': 20, 'V': 21, 'W': 22, 'X': 23, 'Y': 24, 'Z': 25}\n",
    "numberToLetter = {0: 'A', 1: 'B', 2: 'C', 3: 'D', 4: 'E', 5: 'F', 6: 'G', 7: 'H', 8: 'I', 9: 'J', 10: 'K', 11: 'L', 12: 'M', 13: 'N', 14: 'O', 15: 'P', 16: 'Q', 17: 'R', 18: 'S', 19: 'T', 20: 'U', 21: 'V', 22: 'W', 23: 'X', 24: 'Y', 25: 'Z'}\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1PGKJ4GU9yI1JVVddAtvuyhyPfL719BUG&export=download\n",
      "To: /Users/alessiayi/Documents/Github/Utec/ai_project5/Models/models.zip\n",
      "100%|██████████| 222M/222M [00:07<00:00, 30.5MB/s] \n"
     ]
    }
   ],
   "source": [
    "# Descarga los modelos entrenados\n",
    "'''url =  'https://drive.google.com/uc?id=18wmT6d4-5tAIuCeS4KkAzCg7yuSARy5m&export=download'\n",
    "output = 'Models/models.zip'\n",
    "gdown.download(url, output, quiet=False)\n",
    "with zipfile.ZipFile(PATH + \"/Models/models.zip\",\"r\") as zip_ref:\n",
    "    zip_ref.extractall(PATH + \"/Models/\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Models.Models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtener images = lista de np arrays que entran al modelo\n",
    "def preprocessing(image_name):\n",
    "    img = cv2.imread(PATH + \"\\\\\" + image_name)\n",
    "\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    ret, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1,1))\n",
    "    mask = cv2.morphologyEx(thresh, cv2.MORPH_DILATE, kernel)\n",
    "    conts = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    conts = imutils.grab_contours(conts)\n",
    "    boxes = []\n",
    "    for cntr in conts:\n",
    "        x,y,w,h = cv2.boundingRect(cntr)\n",
    "        cv2.rectangle(img, (x, y), (x+w, y+h), (0,0,255), 1)\n",
    "        boxes.append((x,y,w,h))\n",
    "    #plt.imshow(img)\n",
    "    #plt.show()\n",
    "    \n",
    "    boxes = sorted(boxes, key=lambda x: (x))\n",
    "    # print(len(boxes))\n",
    "    prom = 0\n",
    "    spaceLetters = []\n",
    "    for i in range(len(boxes)-1):\n",
    "        x = boxes[i][0]\n",
    "        y = boxes[i][1]\n",
    "        w = boxes[i][2]\n",
    "        h = boxes[i][3]\n",
    "        tmp = boxes[i+1][0]-(x+w)\n",
    "        prom+=tmp\n",
    "        spaceLetters.append(tmp)\n",
    "    prom = prom/(len(boxes)-1) + 5\n",
    "    # print(\"prom: \", math.ceil(prom))\n",
    "    spaces = []\n",
    "    for i in range(len(spaceLetters)):\n",
    "        # print(boxes[i+1][0]-(x+w), math.ceil(prom))\n",
    "        if (spaceLetters[i]) > math.ceil(prom):\n",
    "            spaces.append(i)\n",
    "\n",
    "    # print(spaces)\n",
    "    # cont = 0\n",
    "    images = []\n",
    "    for e, i in enumerate(boxes):\n",
    "        x = i[0]\n",
    "        y = i[1]\n",
    "        w = i[2]\n",
    "        h = i[3]\n",
    "        cropped = thresh[y:y+h, x:x+w]\n",
    "        # inverted = 255 - cropped\n",
    "        # print(cropped.shape)\n",
    "        height = cropped.shape[0]\n",
    "        width = cropped.shape[1]\n",
    "        if (height > width):\n",
    "            diff = height - width\n",
    "            padding = cv2.copyMakeBorder(cropped,30,30,30+int(diff/2),30+int(diff/2),cv2.BORDER_CONSTANT,value=[0,0,0])\n",
    "        elif (height == width):\n",
    "            padding = cv2.copyMakeBorder(cropped,30,30,30,30,cv2.BORDER_CONSTANT,value=[0,0,0])\n",
    "        else:\n",
    "            diff = width - height\n",
    "            padding = cv2.copyMakeBorder(cropped,30+int(diff/2),30+int(diff/2),30,30,cv2.BORDER_CONSTANT,value=[0,0,0])\n",
    "        resized = cv2.resize(padding, (28, 28))\n",
    "        for ii in range(resized.shape[0]):\n",
    "            for jj in range(resized.shape[1]):\n",
    "                if resized[ii][jj] > 0:\n",
    "                    resized[ii][jj] = 255\n",
    "        images.append(resized.astype('float32'))    \n",
    "        # if e < 9:\n",
    "        #plt.imshow(resized)\n",
    "        #plt.show()\n",
    "        # if cont in spaces:\n",
    "        #     blankSpace = np.zeros([28,28,1],dtype=np.uint8)\n",
    "        #     blankSpace.fill(255)\n",
    "        #     images.append(blankSpace.astype('float32'))  \n",
    "        #     plt.imshow(blankSpace)\n",
    "        #     plt.show()\n",
    "        # cont+=1\n",
    "    return images, spaces\n",
    "    print(len(images))\n",
    "    print(type(images[0]))\n",
    "    print(images[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testea\n",
    "def tester(images, spaces, model):\n",
    "    transformToTensor = transforms.ToTensor()\n",
    "    imageTensors = [transformToTensor(np.array(img)) for img in images]\n",
    "    imageBatch = torch.utils.data.DataLoader(dataset=imageTensors, batch_size=64, shuffle=False)\n",
    "\n",
    "    batch = 0\n",
    "    predictText = []\n",
    "    for imgBatch in imageBatch:\n",
    "        imgBatch = imgBatch.to(device)\n",
    "        labelBatchPred = model(imgBatch)\n",
    "\n",
    "        labelBatchPred = labelBatchPred.to('cpu')\n",
    "        imgBatch = imgBatch.to('cpu')\n",
    "        #print(labelBatchPred[0])\n",
    "        _, predBatch = torch.max(labelBatchPred, 1)\n",
    "\n",
    "        group = 0\n",
    "        n = len(imgBatch)\n",
    "        ok = 1\n",
    "        while(group < 4 and ok):\n",
    "            plt.figure(figsize = (25, 10))\n",
    "            r, c = 1, 16\n",
    "            for i in range(16):\n",
    "                plt.subplot(r, c, i+1)\n",
    "                plt.imshow(imgBatch[16*group + i].permute(1, 2, 0))\n",
    "                #plt.xlabel(str(64*batch + 16*group + i + 1) + \": \" + numberToLetter[predBatch[16*group + i].item()] + \" (\" + numberToLetter[np.argmax(y_data[16*group + i])] + \")\", fontsize = 15)\n",
    "                predictLetter = numberToLetter[predBatch[16*group + i].item()]\n",
    "                predictText.append(predictLetter)\n",
    "                plt.xlabel(str(64*batch + 16*group + i + 1) + \": \" + predictLetter,fontsize = 15)\n",
    "                if 16*group + i + 1 == n:\n",
    "                    ok = 0\n",
    "                    break\n",
    "            plt.show()\n",
    "            #print(\"\")\n",
    "            group += 1\n",
    "        batch += 1\n",
    "\n",
    "    finalText = \"\"\n",
    "    for i in range(len(predictText)):\n",
    "        finalText += predictText[i]\n",
    "        # print(predictText[i])\n",
    "        if i in spaces:\n",
    "            finalText += \" \"\n",
    "            # print(\" \")\n",
    "    return finalText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(1, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (11): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Linear(in_features=128, out_features=26, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carga el modelo y lo envia a device\n",
    "#model = torch.load(PATH + '/Models/AlexNet.pt', map_location=torch.device('cpu'))\n",
    "model1 = torch.load(PATH + '/Models/Lenet5.pt')\n",
    "model1 = model1.to(device)\n",
    "model1.eval()\n",
    "\n",
    "model2 = torch.load(PATH + '/Models/AlexNet.pt')\n",
    "model2 = model2.to(device)\n",
    "model2.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "\n",
    "def initiate_camera(seconds, out_name):\n",
    "    st = time.time()\n",
    "    iteration = 0\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        raise IOError(\"Cannot open webcam\")\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        # frame = cv2.resize(frame, None, fx = 0.5, fy = 0.5, interpolation=cv2.INTER_AREA)\n",
    "        cv2.imshow('Input', frame)\n",
    "        cur_time = time.time()\n",
    "        elapsed_time = cur_time - st\n",
    "\n",
    "        if elapsed_time > iteration * seconds:\n",
    "            cv2.imwrite(out_name, frame)\n",
    "            iteration += 1\n",
    "            #Aquí debería ir el código que manda la imagen (frame) al separador de letras.\n",
    "            images, spaces = preprocessing(out_name)\n",
    "            text1 = \"\"\n",
    "            text2 = \"\"\n",
    "            if len(images) > 0:\n",
    "                text1 = tester(images, spaces, model1)\n",
    "                text2 = tester(images, spaces, model2)\n",
    "            else:\n",
    "                text1 = \"\"\n",
    "                text2 = \"\"\n",
    "            #frame contiene la imagen como valor, y la imagen capturada como archivo se guarda en out_name\n",
    "            print(text1)\n",
    "            print(text2)\n",
    "        c = cv2.waitKey(1)\n",
    "        if c == 27:\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initiate_camera(10, \"out.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
